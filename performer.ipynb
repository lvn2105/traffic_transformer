{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1963771874.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Lucia\\AppData\\Local\\Temp\\ipykernel_15220\\1963771874.py\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    Returns:\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def relu_kernel_transformation(data,\n",
    "                               is_query,\n",
    "                               projection_matrix=None,\n",
    "                               numerical_stabilizer=0.001):\n",
    "  \"\"\"Computes features for the ReLU-kernel.\n",
    "  Computes random features for the ReLU kernel from\n",
    "  https://arxiv.org/pdf/2009.14794.pdf.\n",
    "  Args:\n",
    "    data: input data tensor of the shape [B, L, H, D], where: B - batch\n",
    "      dimension, L - attention dimensions, H - heads, D - features.\n",
    "    is_query: indicates whether input data is a query oor key tensor.\n",
    "    projection_matrix: random Gaussian matrix of shape [M, D], where M stands\n",
    "      for the number of random features and each D x D sub-block has pairwise\n",
    "      orthogonal rows.\n",
    "    numerical_stabilizer: small positive constant for numerical stability.\n",
    "  Returns:\n",
    "    Corresponding kernel feature map.\n",
    "  \"\"\"\n",
    "  del is_query\n",
    "  if projection_matrix is None:\n",
    "    return tf.nn.relu(data) + numerical_stabilizer\n",
    "  else:\n",
    "    ratio = 1.0 / tf.math.sqrt(\n",
    "        tf.dtypes.cast(projection_matrix.shape[0], tf.float32))\n",
    "    data_dash = ratio * tf.einsum(\"blhd,md->blhm\", data, projection_matrix)\n",
    "    return tf.nn.relu(data_dash) + numerical_stabilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_kernel_transformation(data,\n",
    "                                  is_query,\n",
    "                                  projection_matrix=None,\n",
    "                                  numerical_stabilizer=0.000001):\n",
    "  \"\"\"Computes random features for the softmax kernel using FAVOR+ mechanism.\n",
    "  Computes random features for the softmax kernel using FAVOR+ mechanism from\n",
    "  https://arxiv.org/pdf/2009.14794.pdf.\n",
    "  Args:\n",
    "    data: input data tensor of the shape [B, L, H, D], where: B - batch\n",
    "      dimension, L - attention dimensions, H - heads, D - features.\n",
    "    is_query: indicates whether input data is a query oor key tensor.\n",
    "    projection_matrix: random Gaussian matrix of shape [M, D], where M stands\n",
    "      for the number of random features and each D x D sub-block has pairwise\n",
    "      orthogonal rows.\n",
    "    numerical_stabilizer: small positive constant for numerical stability.\n",
    "  Returns:\n",
    "    Corresponding kernel feature map.\n",
    "  \"\"\"\n",
    "  data_normalizer = 1.0 / (\n",
    "      tf.math.sqrt(tf.math.sqrt(tf.dtypes.cast(data.shape[-1], tf.float32))))\n",
    "  data = data_normalizer * data\n",
    "  ratio = 1.0 / tf.math.sqrt(\n",
    "      tf.dtypes.cast(projection_matrix.shape[0], tf.float32))\n",
    "  data_dash = tf.einsum(\"blhd,md->blhm\", data, projection_matrix)\n",
    "  diag_data = tf.math.square(data)\n",
    "  diag_data = tf.math.reduce_sum(\n",
    "      diag_data, axis=tf.keras.backend.ndim(data) - 1)\n",
    "  diag_data = diag_data / 2.0\n",
    "  diag_data = tf.expand_dims(diag_data, axis=tf.keras.backend.ndim(data) - 1)\n",
    "  last_dims_t = (len(data_dash.shape) - 1,)\n",
    "  attention_dims_t = (len(data_dash.shape) - 3,)\n",
    "  if is_query:\n",
    "    data_dash = ratio * (\n",
    "        tf.math.exp(data_dash - diag_data - tf.math.reduce_max(\n",
    "            data_dash, axis=last_dims_t, keepdims=True)) + numerical_stabilizer)\n",
    "  else:\n",
    "    data_dash = ratio * (\n",
    "        tf.math.exp(data_dash - diag_data - tf.math.reduce_max(\n",
    "            data_dash, axis=last_dims_t + attention_dims_t, keepdims=True)) +\n",
    "        numerical_stabilizer)\n",
    "\n",
    "  return data_dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sincos_softmax_kernel_feature_creator(data,\n",
    "                                          projection_matrix,\n",
    "                                          attention_dims_t,\n",
    "                                          batch_dims_t,\n",
    "                                          precision,\n",
    "                                          normalize_data=True):\n",
    "  \"\"\"Constructs kernel sin-cos features for fast softmax attention.\n",
    "  Args:\n",
    "    data: input for which features are computes\n",
    "    projection_matrix: random matrix used to compute features\n",
    "    attention_dims_t: tuple of attention dimensions\n",
    "    batch_dims_t: tuple of batch dimensions\n",
    "    precision: precision parameter\n",
    "    normalize_data: predicate indicating whether data should be normalized.\n",
    "  Returns:\n",
    "    Random features for fast softmax attention.\n",
    "  \"\"\"\n",
    "  if normalize_data:\n",
    "    # We have: exp(qk^T/sqrt{d}) = exp(|q|^2/2sqrt{d}) * exp(|k|^2/2sqrt{d}) *\n",
    "    # exp(-(|q*c-k*c|^2)/2), where c = 1.0 / sqrt{sqrt{d}}.\n",
    "    data_normalizer = 1.0 / (tf.math.sqrt(tf.math.sqrt(data.shape[-1])))\n",
    "  else:\n",
    "    data_normalizer = 1.0\n",
    "  ratio = 1.0 / tf.math.sqrt(projection_matrix.shape[0])\n",
    "  data_mod_shape = data.shape[0:len(batch_dims_t)] + projection_matrix.shape\n",
    "  data_thick_random_matrix = .zeros(data_mod_shape) + projection_matrix\n",
    "\n",
    "  data_dash = lax.dot_general(\n",
    "      data_normalizer * data,\n",
    "      data_thick_random_matrix,\n",
    "      (((data.ndim - 1,), (data_thick_random_matrix.ndim - 1,)),\n",
    "       (batch_dims_t, batch_dims_t)),\n",
    "      precision=precision)\n",
    "  data_dash_cos = ratio * jnp.cos(data_dash)\n",
    "  data_dash_sin = ratio * jnp.sin(data_dash)\n",
    "  data_dash = jnp.concatenate((data_dash_cos, data_dash_sin), axis=-1)\n",
    "\n",
    "  # Constructing D_data and data^{'}\n",
    "  diag_data = jnp.square(data)\n",
    "  diag_data = jnp.sum(diag_data, axis=data.ndim - 1)\n",
    "  diag_data = (diag_data / 2.0) * data_normalizer * data_normalizer\n",
    "  diag_data = jnp.expand_dims(diag_data, axis=data.ndim - 1)\n",
    "  # Additional renormalization for numerical stability\n",
    "  data_renormalizer = jnp.max(diag_data, attention_dims_t, keepdims=True)\n",
    "  diag_data -= data_renormalizer\n",
    "  diag_data = jnp.exp(diag_data)\n",
    "  data_prime = data_dash * diag_data\n",
    "  return data_prime"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f764d425ba5d7be8263b8fee07da2f2fdbd0381455a9b7a24eba6a289d5f591"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
