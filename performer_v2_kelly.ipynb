{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70yJX_h9yA-F",
        "outputId": "b7c0e01a-3bcc-4bf1-c922-33829c43e521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n"
          ]
        }
      ],
      "source": [
        "#setup \n",
        "import os\n",
        "import datetime\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "!pip install scikit-learn\n",
        "import sklearn\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (4, 3)\n",
        "mpl.rcParams['axes.grid'] = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnPnRoIYyeOy"
      },
      "outputs": [],
      "source": [
        "new_table = pd.read_csv('https://raw.githubusercontent.com/giobbu/App_Traff_Forecast_DeapLearn/master/data/Flow_BEL_street_30min.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0JEA8J30c5D",
        "outputId": "1f5c650e-bca4-42a7-fe4b-37e63ab482bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  street_index  mean_flow\n",
            "0          0.0   4.048023\n",
            "1          1.0  16.350282\n",
            "2          2.0   6.511299\n",
            "3          3.0   7.681850\n",
            "4          4.0   9.484463\n",
            "\n",
            "considering a average traffic flow of 20 per street\n",
            "\n",
            "mean traffic flow 20 ---> number of street segments: 1683\n"
          ]
        }
      ],
      "source": [
        "# this source: \n",
        "# the https://www.kaggle.com/code/giobbu/seasonal-persistence-model/notebook#Results-Comparison-between-Seasonal-model-(baseline)-and-LSTM-encoder-decoder-model\n",
        "# selects the roads that have an average traffic flow of 10 or larger, we also do this, this code is from the notebook listed above \n",
        "\n",
        "table_index = new_table.iloc[:,1:]\n",
        "ALL_STREETS = list(table_index.columns.values)\n",
        "\n",
        "mean_flow =[]\n",
        "new_street=[]\n",
        "\n",
        "mean_value = 20\n",
        "\n",
        "for street in ALL_STREETS:\n",
        "    \n",
        "    single_street=table_index[street]\n",
        "    mean = np.mean(single_street)\n",
        "    mean_flow.append(mean)\n",
        "    new_street.append(street)\n",
        "    \n",
        "    \n",
        "df_mean_flow = pd.DataFrame({'street_index':new_street, 'mean_flow': mean_flow})\n",
        "print('')\n",
        "print(df_mean_flow.head())\n",
        "print('')\n",
        "\n",
        "STREETS = df_mean_flow[(df_mean_flow['mean_flow'] >= mean_value)] \n",
        "STREETS = STREETS.sort_values(by=['street_index'])\n",
        "STREETS = list(STREETS.street_index)\n",
        "\n",
        "keys_dim = 1683\n",
        "keys_dim_time = 1686\n",
        "\n",
        "print('considering a average traffic flow of ' + str(mean_value)+' per street')\n",
        "print('')\n",
        "print('mean traffic flow '+str(mean_value)+ ' ---> number of street segments: ' + str(len(STREETS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8PW_uZbWlBB"
      },
      "outputs": [],
      "source": [
        "new_table['datetime'] = pd.to_datetime(new_table['datetime'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ZfYYEjq-W7Rv",
        "outputId": "9d0ba1ca-25dc-4d17-da56-b477916763d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-ffee7ced4756>:1: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
            "  plt.plot(new_table['datetime'],new_table.mean(axis = 1))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3061e36c70>]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(new_table['datetime'],new_table.mean(axis = 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSCCJ46kYnfL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.gen_array_ops import fake_quant_with_min_max_vars_per_channel\n",
        "#we need to create \"windows\" in the data --> \n",
        "#X: input tensor : use a window of size s, lets say 5, as X\n",
        "#Y: output vector : traffic for hour six predicted based on the previous window \n",
        "\n",
        "#this is the window function for multiple input features and multiple output pairs\n",
        "#what's the difference between df_to_x_y2 and df_to_x_y --> the first one is just for one input vector (ie the data from one street) this \n",
        "#version accepts many columns of data (all the street values and the transformed time data)\n",
        "def df_to_x_y2(positional_data,non_positional, window_size): \n",
        "  #df_as_np = df.to_numpy()\n",
        "  print(positional_data.shape)\n",
        "  print(non_positional.shape)\n",
        "  X = []\n",
        "  Y = []\n",
        "  for i in range((len(positional_data))-window_size-1):\n",
        "    row = [r for r in positional_data[i:i+window_size]]\n",
        "    \n",
        "    #The line below makes the last value in the batch 0 (relative to what we are predicting, \n",
        "    #traffic flow rate, the positional information is still encoded )\n",
        "    row.append(positional_data[i+window_size+1] - non_positional[i+window_size+1]) \n",
        "    X.append(row)\n",
        "    \n",
        "    label = [non_positional[i+window_size][0:]] \n",
        "    Y.append(label)\n",
        "  return np.array(X), np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9ddvo5P3o_p"
      },
      "outputs": [],
      "source": [
        "#this is for transforming datetime to recognizable inputs \n",
        "#sin and cos transformation for hour of the day \n",
        "df = new_table\n",
        "df = df[STREETS + ['datetime']] \n",
        " #this removes all of the streets with aveage flow <10 \n",
        "\n",
        "df.head()\n",
        "\n",
        "time = df['datetime'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwhYU7pOk63h"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(df):\n",
        "  import datetime as dt\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "  df = pd.Series(df)\n",
        "  hour = df.dt.hour.to_numpy().astype('float32')\n",
        "  hour_sin = np.sin(hour*2* np.pi/23)\n",
        "  hour_cos = np.cos(hour*2* np.pi/23)\n",
        "  \n",
        "  day_of_week = df.dt.dayofweek.to_numpy()\n",
        "  day_of_week_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "  day_of_week = day_of_week.reshape(-1, 1)\n",
        "  day_of_week = day_of_week_scaler.fit_transform(day_of_week)\n",
        "  day_of_week = day_of_week[:,0]\n",
        "  \n",
        "  pos_encoding_val = hour_sin + hour_cos + day_of_week\n",
        "  pos_encoding_val = pos_encoding_val.reshape(-1,1)\n",
        "  final_scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  pos_encoding_val = final_scaler.fit_transform(pos_encoding_val)\n",
        "  return pos_encoding_val\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJu55qlMeoKk",
        "outputId": "3b74968b-7e71-4623-fd3d-ace4ce504d20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.56847003],\n",
              "       [0.56847003],\n",
              "       [0.61674907],\n",
              "       ...,\n",
              "       [0.64311181],\n",
              "       [0.70677715],\n",
              "       [0.70677715]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#test positoinal_encoding function \n",
        "positional_encoding(time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_q9uHmeoKk"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, date_time_info,time_weight):\n",
        "    super().__init__()\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    self.time_weight = time_weight\n",
        "    self.scaler = MinMaxScaler(feature_range=(0,1))\n",
        "    self.pos_encoding = positional_encoding(date_time_info)\n",
        "\n",
        "  def call(self, x):\n",
        "    print(x.shape)\n",
        "    print(type(x))\n",
        "    print(x)\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.scaler.fit_transform(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    print(self.pos_encoding.shape)\n",
        "    x_positioned = np.add(x*(1-self.time_weight), (self.time_weight * self.pos_encoding))\n",
        "    print(x.shape)\n",
        "    x_final,y_final= df_to_x_y2(x_positioned,x,window_size=12) \n",
        "    x_final = tf.constant(x_final)\n",
        "    y_final = tf.constant(y_final)\n",
        "    return x_final,y_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fYBUG1beoKk",
        "outputId": "4910d75b-c7f9-4235-95bb-8b70602bab55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2832, 1683)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[ 2.  0.  0. ...  0.  0.  0.]\n",
            " [ 1.  0.  0. ...  1.  1.  0.]\n",
            " [ 3.  1.  0. ...  1.  0.  0.]\n",
            " ...\n",
            " [31. 14.  4. ... 19.  8. 13.]\n",
            " [29. 16.  1. ... 16.  6. 27.]\n",
            " [21. 27.  6. ... 14.  4. 15.]], shape=(2832, 1683), dtype=float32)\n",
            "(2832, 1)\n",
            "(2832, 1683)\n",
            "(2832, 1683)\n",
            "(2832, 1683)\n",
            "shape1 tf.Tensor(\n",
            "[[0.23351046 0.22738801 0.22738801 ... 0.22738801 0.22738801 0.22738801]\n",
            " [0.23044924 0.22738801 0.22738801 ... 0.22999671 0.23538801 0.22738801]\n",
            " [0.2558833  0.25038061 0.24669963 ... 0.24930832 0.24669963 0.24669963]\n",
            " ...\n",
            " [0.2455972  0.24621695 0.24711613 ... 0.24514467 0.25053597 0.24474186]\n",
            " [0.24253597 0.24253597 0.24711613 ... 0.24253597 0.25053597 0.24694774]\n",
            " [0.21949069 0.21416954 0.2215315  ... 0.21805324 0.2215315  0.2215315 ]], shape=(13, 1683), dtype=float64)\n",
            "(2832, 1683)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[ 2.  0.  0. ...  0.  0.  0.]\n",
            " [ 1.  0.  0. ...  1.  1.  0.]\n",
            " [ 3.  1.  0. ...  1.  0.  0.]\n",
            " ...\n",
            " [31. 14.  4. ... 19.  8. 13.]\n",
            " [29. 16.  1. ... 16.  6. 27.]\n",
            " [21. 27.  6. ... 14.  4. 15.]], shape=(2832, 1683), dtype=float32)\n",
            "(2832, 1)\n",
            "(2832, 1683)\n",
            "(2832, 1683)\n",
            "(2832, 1683)\n",
            "shape2 tf.Tensor(\n",
            "[[0.01020408 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.00510204 0.         0.         ... 0.00434783 0.01333333 0.        ]\n",
            " [0.01530612 0.00613497 0.         ... 0.00434783 0.         0.        ]\n",
            " ...\n",
            " [0.00510204 0.00613497 0.00763359 ... 0.00434783 0.01333333 0.00367647]\n",
            " [0.         0.         0.00763359 ... 0.         0.01333333 0.00735294]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]], shape=(13, 1683), dtype=float64)\n"
          ]
        }
      ],
      "source": [
        "#testing the positional embedding class \n",
        "positional_em = PositionalEmbedding(time,0.4)\n",
        "positional_em2 = PositionalEmbedding(time,0)\n",
        "\n",
        "print('shape1',positional_em(df[STREETS].to_numpy())[0][0])\n",
        "print('shape2',positional_em2(df[STREETS].to_numpy())[0][0])\n",
        "\n",
        "x1_df = df[STREETS + ['datetime']].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title util.py \n",
        "# coding=utf-8\n",
        "# Copyright 2022 The Google Research Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Keras-based einsum layer.\n",
        "Copied from\n",
        "https://github.com/tensorflow/models/blob/master/official/nlp/modeling/layers/dense_einsum.py.\n",
        "\"\"\"\n",
        "# pylint: disable=g-classes-have-attributes\n",
        "\n",
        "_CHR_IDX = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\"]\n",
        "\n",
        "\n",
        "#@tf.keras.utils.register_keras_serializable(package=\"Text\")\n",
        "class DenseEinsum(tf.keras.layers.Layer):\n",
        "  \"\"\"A densely connected layer that uses tf.einsum as the backing computation.\n",
        "  This layer can perform einsum calculations of arbitrary dimensionality.\n",
        "  Arguments:\n",
        "    output_shape: Positive integer or tuple, dimensionality of the output space.\n",
        "    num_summed_dimensions: The number of dimensions to sum over. Standard 2D\n",
        "      matmul should use 1, 3D matmul should use 2, and so forth.\n",
        "    activation: Activation function to use. If you don't specify anything, no\n",
        "      activation is applied\n",
        "      (ie. \"linear\" activation: `a(x) = x`).\n",
        "    use_bias: Boolean, whether the layer uses a bias vector.\n",
        "    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
        "    bias_initializer: Initializer for the bias vector.\n",
        "    kernel_regularizer: Regularizer function applied to the `kernel` weights\n",
        "      matrix.\n",
        "    bias_regularizer: Regularizer function applied to the bias vector.\n",
        "    activity_regularizer: Regularizer function applied to the output of the\n",
        "      layer (its \"activation\")..\n",
        "    kernel_constraint: Constraint function applied to the `kernel` weights\n",
        "      matrix.\n",
        "    bias_constraint: Constraint function applied to the bias vector.\n",
        "  Input shape:\n",
        "    N-D tensor with shape: `(batch_size, ..., input_dim)`. The most common\n",
        "      situation would be a 2D input with shape `(batch_size, input_dim)`.\n",
        "  Output shape:\n",
        "    N-D tensor with shape: `(batch_size, ..., units)`. For instance, for a 2D\n",
        "      input with shape `(batch_size, input_dim)`, the output would have shape\n",
        "      `(batch_size, units)`.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               output_shape,\n",
        "               num_summed_dimensions=1,\n",
        "               activation=None,\n",
        "               use_bias=True,\n",
        "               kernel_initializer=\"glorot_uniform\",\n",
        "               bias_initializer=\"zeros\",\n",
        "               kernel_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               activity_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               **kwargs):\n",
        "    super(DenseEinsum, self).__init__(**kwargs)\n",
        "    self._output_shape = output_shape if isinstance(\n",
        "        output_shape, (list, tuple)) else (output_shape,)\n",
        "    self._activation = tf.keras.activations.get(activation)\n",
        "    self._use_bias = use_bias\n",
        "    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
        "    self._bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
        "    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)\n",
        "    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)\n",
        "    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)\n",
        "    self._bias_constraint = tf.keras.constraints.get(bias_constraint)\n",
        "    self._num_summed_dimensions = num_summed_dimensions\n",
        "    self._einsum_string = None\n",
        "\n",
        "  def _build_einsum_string(self, free_input_dims, bound_dims, output_dims):\n",
        "    input_str = \"\"\n",
        "    kernel_str = \"\"\n",
        "    output_str = \"\"\n",
        "    letter_offset = 0\n",
        "    for i in range(free_input_dims):\n",
        "      char = _CHR_IDX[i + letter_offset]\n",
        "      input_str += char\n",
        "      output_str += char\n",
        "\n",
        "    letter_offset += free_input_dims\n",
        "    for i in range(bound_dims):\n",
        "      char = _CHR_IDX[i + letter_offset]\n",
        "      input_str += char\n",
        "      kernel_str += char\n",
        "\n",
        "    letter_offset += bound_dims\n",
        "    for i in range(output_dims):\n",
        "      char = _CHR_IDX[i + letter_offset]\n",
        "      kernel_str += char\n",
        "      output_str += char\n",
        "\n",
        "    return input_str + \",\" + kernel_str + \"->\" + output_str\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    input_shape = tf.TensorShape(input_shape)\n",
        "    input_rank = input_shape.rank\n",
        "    free_input_dims = input_rank - self._num_summed_dimensions\n",
        "    output_dims = len(self._output_shape)\n",
        "\n",
        "    self._einsum_string = self._build_einsum_string(free_input_dims,\n",
        "                                                    self._num_summed_dimensions,\n",
        "                                                    output_dims)\n",
        "\n",
        "    # This is only saved for testing purposes.\n",
        "    self._kernel_shape = (\n",
        "        input_shape[free_input_dims:].concatenate(self._output_shape))\n",
        "\n",
        "    self._kernel = self.add_weight(\n",
        "        \"kernel\",\n",
        "        shape=self._kernel_shape,\n",
        "        initializer=self._kernel_initializer,\n",
        "        regularizer=self._kernel_regularizer,\n",
        "        constraint=self._kernel_constraint,\n",
        "        dtype=self.dtype,\n",
        "        trainable=True)\n",
        "    if self._use_bias:\n",
        "      self._bias = self.add_weight(\n",
        "          \"bias\",\n",
        "          shape=self._output_shape,\n",
        "          initializer=self._bias_initializer,\n",
        "          regularizer=self._bias_regularizer,\n",
        "          constraint=self._bias_constraint,\n",
        "          dtype=self.dtype,\n",
        "          trainable=True)\n",
        "    else:\n",
        "      self._bias = None\n",
        "    super(DenseEinsum, self).build(input_shape)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        \"output_shape\":\n",
        "            self._output_shape,\n",
        "        \"num_summed_dimensions\":\n",
        "            self._num_summed_dimensions,\n",
        "        \"activation\":\n",
        "            tf.keras.activations.serialize(self._activation),\n",
        "        \"use_bias\":\n",
        "            self._use_bias,\n",
        "        \"kernel_initializer\":\n",
        "            tf.keras.initializers.serialize(self._kernel_initializer),\n",
        "        \"bias_initializer\":\n",
        "            tf.keras.initializers.serialize(self._bias_initializer),\n",
        "        \"kernel_regularizer\":\n",
        "            tf.keras.regularizers.serialize(self._kernel_regularizer),\n",
        "        \"bias_regularizer\":\n",
        "            tf.keras.regularizers.serialize(self._bias_regularizer),\n",
        "        \"activity_regularizer\":\n",
        "            tf.keras.regularizers.serialize(self._activity_regularizer),\n",
        "        \"kernel_constraint\":\n",
        "            tf.keras.constraints.serialize(self._kernel_constraint),\n",
        "        \"bias_constraint\":\n",
        "            tf.keras.constraints.serialize(self._bias_constraint)\n",
        "    }\n",
        "    base_config = super(DenseEinsum, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "  def call(self, inputs):\n",
        "    ret = tf.einsum(self._einsum_string, inputs, self._kernel)\n",
        "    if self._use_bias:\n",
        "      ret += self._bias\n",
        "    if self._activation is not None:\n",
        "      ret = self._activation(ret)\n",
        "    return ret"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XPNQuM0wfRTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox1S0_treoKk"
      },
      "outputs": [],
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2022 The Google Research Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Implementation of multiheaded FAVOR-attention & FAVOR-self-attention layers.\n",
        "Prefix Sum Tensorflow implementation by Valerii Likhosherstov.\n",
        "\"\"\"\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "BIG_CONSTANT = 1e8\n",
        "\n",
        "def create_products_of_givens_rotations(dim, seed):\n",
        "  r\"\"\"Constructs a 2D-tensor which is a product of Givens random rotations.\n",
        "  Constructs a 2D-tensor of the form G_1 * ... * G_k, where G_i is a Givens\n",
        "  random rotation. The resulting tensor mimics a matrix taken uniformly at\n",
        "  random form the orthogonal group.\n",
        "  Args:\n",
        "    dim: number of rows/columns of the resulting 2D-tensor.\n",
        "    seed: random seed.\n",
        "  Returns:\n",
        "    The product of Givens random rotations.\n",
        "  \"\"\"\n",
        "  nb_givens_rotations = dim * int(math.ceil(math.log(float(dim))))\n",
        "  q = np.eye(dim, dim)\n",
        "  np.random.seed(seed)\n",
        "  for _ in range(nb_givens_rotations):\n",
        "    random_angle = math.pi * np.random.uniform()\n",
        "    random_indices = np.random.choice(dim, 2)\n",
        "    index_i = min(random_indices[0], random_indices[1])\n",
        "    index_j = max(random_indices[0], random_indices[1])\n",
        "    slice_i = q[index_i]\n",
        "    slice_j = q[index_j]\n",
        "    new_slice_i = math.cos(random_angle) * slice_i + math.sin(\n",
        "        random_angle) * slice_j\n",
        "    new_slice_j = -math.sin(random_angle) * slice_i + math.cos(\n",
        "        random_angle) * slice_j\n",
        "    q[index_i] = new_slice_i\n",
        "    q[index_j] = new_slice_j\n",
        "  return tf.cast(tf.constant(q), dtype=tf.float32)\n",
        "\n",
        "\n",
        "\n",
        "def create_projection_matrix(m, d, seed=0, scaling=0, struct_mode=False):\n",
        "  r\"\"\"Constructs the matrix of random projections.\n",
        "  Constructs a matrix of random orthogonal projections. Each projection vector\n",
        "  has direction chosen uniformly at random and either deterministic length\n",
        "  \\sqrt{d} or length taken from the \\chi(d) distribution (in the latter case\n",
        "  marginal distributions of the projections are d-dimensional Gaussian vectors\n",
        "  with associated identity covariance matrix).\n",
        "  Args:\n",
        "    m: number of random projections.\n",
        "    d: dimensionality of each random projection.\n",
        "    seed: random seed used to construct projections.\n",
        "    scaling: 1 if all the random projections need to be renormalized to have\n",
        "      length \\sqrt{d}, 0 if the lengths of random projections should follow\n",
        "      \\chi(d) distribution.\n",
        "    struct_mode: if True then products of Givens rotations will be used to\n",
        "      construct random orthogonal matrix. This bypasses Gram-Schmidt\n",
        "      orthogonalization.\n",
        "  Returns:\n",
        "    The matrix of random projections of the shape [m, d].\n",
        "  \"\"\"\n",
        "  nb_full_blocks = int(m / d)\n",
        "  block_list = []\n",
        "  current_seed = seed\n",
        "  for _ in range(nb_full_blocks):\n",
        "    if struct_mode:\n",
        "      q = create_products_of_givens_rotations(d, seed)\n",
        "    else:\n",
        "      unstructured_block = tf.random.normal((d, d), seed=current_seed)\n",
        "      q, _ = tf.linalg.qr(unstructured_block)\n",
        "      q = tf.transpose(q)\n",
        "    block_list.append(q)\n",
        "    current_seed += 1\n",
        "  remaining_rows = m - nb_full_blocks * d\n",
        "  if remaining_rows > 0:\n",
        "    if struct_mode:\n",
        "      q = create_products_of_givens_rotations(d, seed)\n",
        "    else:\n",
        "      unstructured_block = tf.random.normal((d, d), seed=current_seed)\n",
        "      q, _ = tf.linalg.qr(unstructured_block)\n",
        "      q = tf.transpose(q)\n",
        "    block_list.append(q[0:remaining_rows])\n",
        "  final_matrix = tf.experimental.numpy.vstack(block_list)\n",
        "  current_seed += 1\n",
        "\n",
        "  if scaling == 0:\n",
        "    multiplier = tf.norm(tf.random.normal((m, d), seed=current_seed), axis=1)\n",
        "  elif scaling == 1:\n",
        "    multiplier = tf.math.sqrt(float(d)) * tf.ones((m))\n",
        "  else:\n",
        "    raise ValueError(\"Scaling must be one of {0, 1}. Was %s\" % scaling)\n",
        "\n",
        "  return tf.linalg.matmul(tf.linalg.diag(multiplier), final_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psd6GGsFeoKl"
      },
      "outputs": [],
      "source": [
        "#This is number 1 of the kernal transformation options, we can add the other options pretty easily I think \n",
        "\n",
        "def relu_kernel_transformation(data,\n",
        "                               is_query,\n",
        "                               projection_matrix=None,\n",
        "                               numerical_stabilizer=0.001):\n",
        "  del is_query\n",
        "  if projection_matrix is None:\n",
        "    return tf.nn.relu(data) + numerical_stabilizer\n",
        "  else:\n",
        "    ratio = 1.0 / tf.math.sqrt(\n",
        "        tf.dtypes.cast(projection_matrix.shape[0], tf.float32))\n",
        "    data_dash = ratio * tf.einsum(\"blhd,md->blhm\", data, projection_matrix)\n",
        "    return tf.nn.relu(data_dash) + numerical_stabilizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_kernel_transformation(data,\n",
        "                                  is_query,\n",
        "                                  projection_matrix=None,\n",
        "                                  numerical_stabilizer=0.000001):\n",
        "  \"\"\"Computes random features for the softmax kernel using FAVOR+ mechanism.\n",
        "  Computes random features for the softmax kernel using FAVOR+ mechanism from\n",
        "  https://arxiv.org/pdf/2009.14794.pdf.\n",
        "  Args:\n",
        "    data: input data tensor of the shape [B, L, H, D], where: B - batch\n",
        "      dimension, L - attention dimensions, H - heads, D - features.\n",
        "    is_query: indicates whether input data is a query oor key tensor.\n",
        "    projection_matrix: random Gaussian matrix of shape [M, D], where M stands\n",
        "      for the number of random features and each D x D sub-block has pairwise\n",
        "      orthogonal rows.\n",
        "    numerical_stabilizer: small positive constant for numerical stability.\n",
        "  Returns:\n",
        "    Corresponding kernel feature map.\n",
        "  \"\"\"\n",
        "  data_normalizer = 1.0 / (\n",
        "      tf.math.sqrt(tf.math.sqrt(tf.dtypes.cast(data.shape[-1], tf.float32))))\n",
        "  data = data_normalizer * data\n",
        "  ratio = 1.0 / tf.math.sqrt(\n",
        "      tf.dtypes.cast(projection_matrix.shape[0], tf.float32))\n",
        "  data_dash = tf.einsum(\"blhd,md->blhm\", data, projection_matrix)\n",
        "  diag_data = tf.math.square(data)\n",
        "  diag_data = tf.math.reduce_sum(\n",
        "      diag_data, axis=tf.keras.backend.ndim(data) - 1)\n",
        "  diag_data = diag_data / 2.0\n",
        "  diag_data = tf.expand_dims(diag_data, axis=tf.keras.backend.ndim(data) - 1)\n",
        "  last_dims_t = (len(data_dash.shape) - 1,)\n",
        "  attention_dims_t = (len(data_dash.shape) - 3,)\n",
        "  if is_query:\n",
        "    data_dash = ratio * (\n",
        "        tf.math.exp(data_dash - diag_data - tf.math.reduce_max(\n",
        "            data_dash, axis=last_dims_t, keepdims=True)) + numerical_stabilizer)\n",
        "  else:\n",
        "    data_dash = ratio * (\n",
        "        tf.math.exp(data_dash - diag_data - tf.math.reduce_max(\n",
        "            data_dash, axis=last_dims_t + attention_dims_t, keepdims=True)) +\n",
        "        numerical_stabilizer)\n",
        "\n",
        "  return data_dash"
      ],
      "metadata": {
        "id": "mcesGJ5awrFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsDuCSsweoKl"
      },
      "outputs": [],
      "source": [
        "#numerator and denominator calculations \n",
        "def noncausal_numerator(qs, ks, vs):\n",
        "  \"\"\"Computes not-normalized FAVOR noncausal attention AV.\n",
        "  Args:\n",
        "    qs: query_prime tensor of the shape [L,B,H,M].\n",
        "    ks: key_prime tensor of the shape [L,B,H,M].\n",
        "    vs: value tensor of the shape [L,B,H,D].\n",
        "  Returns:\n",
        "    Not-normalized FAVOR noncausal attention AV.\n",
        "  \"\"\"\n",
        "  kvs = tf.einsum(\"lbhm,lbhd->bhmd\", ks, vs)\n",
        "  return tf.einsum(\"lbhm,bhmd->lbhd\", qs, kvs)\n",
        "\n",
        "\n",
        "def noncausal_denominator(qs, ks):\n",
        "  \"\"\"Computes FAVOR normalizer in noncausal attention.\n",
        "  Args:\n",
        "    qs: query_prime tensor of the shape [L,B,H,M].\n",
        "    ks: key_prime tensor of the shape [L,B,H,M].\n",
        "  Returns:\n",
        "    FAVOR normalizer in noncausal attention.\n",
        "  \"\"\"\n",
        "  all_ones = tf.ones([ks.shape[0]])\n",
        "  ks_sum = tf.einsum(\"lbhm,l->bhm\", ks, all_ones)\n",
        "  return tf.einsum(\"lbhm,bhm->lbh\", qs, ks_sum)\n",
        "\n",
        "\n",
        "@tf.custom_gradient\n",
        "def causal_numerator(qs, ks, vs):\n",
        "  \"\"\"Computes not-normalized FAVOR causal attention A_{masked}V.\n",
        "  Args:\n",
        "    qs: query_prime tensor of the shape [L,B,H,M].\n",
        "    ks: key_prime tensor of the shape [L,B,H,M].\n",
        "    vs: value tensor of the shape [L,B,H,D].\n",
        "  Returns:\n",
        "    Not-normalized FAVOR causal attention A_{masked}V.\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  sums = tf.zeros_like(tf.einsum(\"ijk,ijl->ijkl\", ks[0], vs[0]))\n",
        "\n",
        "  for index in range(qs.shape[0]):\n",
        "    sums = sums + tf.einsum(\"ijk,ijl->ijkl\", ks[index], vs[index])\n",
        "    result.append(tf.einsum(\"ijkl,ijk->ijl\", sums, qs[index])[None, Ellipsis])\n",
        "\n",
        "  result = tf.concat(result, axis=0)\n",
        "\n",
        "  def grad(res_grad):\n",
        "\n",
        "    grads = tf.zeros_like(tf.einsum(\"ijk,ijl->ijkl\", ks[0], vs[0]))\n",
        "\n",
        "    gr_sums = sums\n",
        "\n",
        "    q_grads = []\n",
        "    k_grads = []\n",
        "    v_grads = []\n",
        "\n",
        "    for index in range(qs.shape[0] - 1, -1, -1):\n",
        "\n",
        "      q_grads.append(\n",
        "          tf.einsum(\"ijkl,ijl->ijk\", gr_sums, res_grad[index])[None, Ellipsis])\n",
        "      grads = grads + tf.einsum(\"ijk,ijl->ijkl\", qs[index], res_grad[index])\n",
        "      k_grads.append(tf.einsum(\"ijkl,ijl->ijk\", grads, vs[index])[None, Ellipsis])\n",
        "      v_grads.append(tf.einsum(\"ijkl,ijk->ijl\", grads, ks[index])[None, Ellipsis])\n",
        "      gr_sums = gr_sums - tf.einsum(\"ijk,ijl->ijkl\", ks[index], vs[index])\n",
        "\n",
        "    q_grads = tf.concat(q_grads[::-1], axis=0)\n",
        "    k_grads = tf.concat(k_grads[::-1], axis=0)\n",
        "    v_grads = tf.concat(v_grads[::-1], axis=0)\n",
        "\n",
        "    return q_grads, k_grads, v_grads\n",
        "\n",
        "  return result, grad\n",
        "\n",
        "\n",
        "@tf.custom_gradient\n",
        "def causal_denominator(qs, ks):\n",
        "  \"\"\"Computes FAVOR normalizer in causal attention.\n",
        "  Args:\n",
        "    qs: query_prime tensor of the shape [L,B,H,M].\n",
        "    ks: key_prime tensor of the shape [L,B,H,M].\n",
        "  Returns:\n",
        "    FAVOR normalizer in causal attention.\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  sums = tf.zeros_like(ks[0])\n",
        "\n",
        "  for index in range(qs.shape[0]):\n",
        "    sums = sums + ks[index]\n",
        "    result.append(tf.reduce_sum(qs[index] * sums, axis=2)[None, Ellipsis])\n",
        "\n",
        "  result = tf.concat(result, axis=0)\n",
        "\n",
        "  def grad(res_grad):\n",
        "\n",
        "    k_grad = tf.zeros_like(ks[0])\n",
        "\n",
        "    gr_sums = sums\n",
        "\n",
        "    q_grads = []\n",
        "    k_grads = []\n",
        "\n",
        "    for index in range(qs.shape[0] - 1, -1, -1):\n",
        "\n",
        "      q_grads.append(\n",
        "          tf.einsum(\"ijk,ij->ijk\", gr_sums, res_grad[index])[None, Ellipsis])\n",
        "      k_grad = k_grad + tf.einsum(\"ijk,ij->ijk\", qs[index], res_grad[index])\n",
        "      k_grads.append(k_grad[None, Ellipsis])\n",
        "      gr_sums = gr_sums - ks[index]\n",
        "\n",
        "    q_grads = tf.concat(q_grads[::-1], axis=0)\n",
        "    k_grads = tf.concat(k_grads[::-1], axis=0)\n",
        "\n",
        "    return q_grads, k_grads\n",
        "\n",
        "  return result, grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC1anNfGeoKl"
      },
      "outputs": [],
      "source": [
        "#this is the new version of the attention code from the transformer version (this is the main calculation of the performer attention class) \n",
        "def favor_attention(query,\n",
        "                    key,\n",
        "                    value,\n",
        "                    kernel_transformation,\n",
        "                    causal,\n",
        "                    projection_matrix=None):\n",
        "  \"\"\"Computes FAVOR normalized attention.\n",
        "  #push again \n",
        "  Args:\n",
        "    query: query tensor.\n",
        "    key: key tensor.\n",
        "    value: value tensor.\n",
        "    kernel_transformation: transformation used to get finite kernel features.\n",
        "    causal: whether attention is causal or not.\n",
        "    projection_matrix: projection matrix to be used.\n",
        "  Returns:\n",
        "    FAVOR normalized attention.\n",
        "  \"\"\"\n",
        "  query_prime = kernel_transformation(query, True,\n",
        "                                      projection_matrix)  # [B,L,H,M]\n",
        "  key_prime = kernel_transformation(key, False, projection_matrix)  # [B,L,H,M]\n",
        "  query_prime = tf.transpose(query_prime, [1, 0, 2, 3])  # [L,B,H,M]\n",
        "  key_prime = tf.transpose(key_prime, [1, 0, 2, 3])  # [L,B,H,M]\n",
        "  value = tf.transpose(value, [1, 0, 2, 3])  # [L,B,H,D]\n",
        "\n",
        "  if causal:\n",
        "    av_attention = causal_numerator(query_prime, key_prime, value)\n",
        "    attention_normalizer = causal_denominator(query_prime, key_prime)\n",
        "  else:\n",
        "    av_attention = noncausal_numerator(query_prime, key_prime, value)\n",
        "    attention_normalizer = noncausal_denominator(query_prime, key_prime)\n",
        "  # TODO(kchoro): Add more comments.\n",
        "  av_attention = tf.transpose(av_attention, [1, 0, 2, 3])\n",
        "  attention_normalizer = tf.transpose(attention_normalizer, [1, 0, 2])\n",
        "  attention_normalizer = tf.expand_dims(attention_normalizer,\n",
        "                                        len(attention_normalizer.shape))\n",
        "  return av_attention / attention_normalizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW27t0A_eoKl"
      },
      "outputs": [],
      "source": [
        "#new attention class (starting with relu_kernel_transformation)\n",
        "class Attention(tf.keras.layers.Layer):\n",
        "  \"\"\"Multi-headed attention layer.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               hidden_size,\n",
        "               num_heads,\n",
        "               dropout_rate,\n",
        "               kernel_transformation=relu_kernel_transformation,\n",
        "               numerical_stabilizer=0.001,\n",
        "               causal=False,\n",
        "               projection_matrix_type=None,\n",
        "               nb_random_features=0):\n",
        "    \"\"\"Initialize Attention.\n",
        "    Args:\n",
        "      hidden_size: int, output dim of hidden layer.\n",
        "      num_heads: int, number of heads to repeat the same attention structure.\n",
        "      dropout_rate: float, dropout rate inside attention for training.\n",
        "      kernel_transformation: transformation used to produce kernel features for\n",
        "        attention.\n",
        "      numerical_stabilizer: used to bound away from zero kernel values.\n",
        "      causal: whether attention is causal or not.\n",
        "      projection_matrix_type: None if Identity should be used, otherwise random\n",
        "        projection matrix will be applied.\n",
        "      nb_random_features: number of random features to be used (relevant only if\n",
        "        projection_matrix is not None).\n",
        "    \"\"\"\n",
        "    if hidden_size % num_heads:\n",
        "      raise ValueError(\n",
        "          \"Hidden size ({}) must be divisible by the number of heads ({}).\"\n",
        "          .format(hidden_size, num_heads))\n",
        "\n",
        "    super(Attention, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_heads = num_heads\n",
        "    self.dropout_rate = dropout_rate\n",
        "    self.kernel_transformation = kernel_transformation\n",
        "    self.numerical_stabilizer = numerical_stabilizer\n",
        "    self.causal = causal\n",
        "    self.projection_matrix_type = projection_matrix_type\n",
        "    self.nb_random_features = nb_random_features\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    \"\"\"Builds the layer.\"\"\"\n",
        "    # Layers for linearly projecting the queries, keys, and values.\n",
        "    size_per_head = self.hidden_size // self.num_heads\n",
        "\n",
        "    def _glorot_initializer(fan_in, fan_out):\n",
        "      limit = math.sqrt(6.0 / (fan_in + fan_out))\n",
        "      return tf.keras.initializers.RandomUniform(minval=-limit, maxval=limit)\n",
        "\n",
        "    attention_initializer = _glorot_initializer(input_shape.as_list()[-1],\n",
        "                                                self.hidden_size)\n",
        "    self.query_dense_layer = DenseEinsum(\n",
        "        output_shape=(self.num_heads, size_per_head),\n",
        "        kernel_initializer=attention_initializer,\n",
        "        use_bias=False,\n",
        "        name=\"query\")\n",
        "    self.key_dense_layer = DenseEinsum(\n",
        "        output_shape=(self.num_heads, size_per_head),\n",
        "        kernel_initializer=attention_initializer,\n",
        "        use_bias=False,\n",
        "        name=\"key\")\n",
        "    self.value_dense_layer = DenseEinsum(\n",
        "        output_shape=(self.num_heads, size_per_head),\n",
        "        kernel_initializer=attention_initializer,\n",
        "        use_bias=False,\n",
        "        name=\"value\")\n",
        "\n",
        "    output_initializer = _glorot_initializer(self.hidden_size, self.hidden_size)\n",
        "    self.output_dense_layer = DenseEinsum(\n",
        "        output_shape=self.hidden_size,\n",
        "        num_summed_dimensions=2,\n",
        "        kernel_initializer=output_initializer,\n",
        "        use_bias=False,\n",
        "        name=\"output_transform\")\n",
        "    super(Attention, self).build(input_shape)\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\n",
        "        \"hidden_size\": self.hidden_size,\n",
        "        \"num_heads\": self.num_heads,\n",
        "        \"dropout_rate\": self.dropout_rate,\n",
        "    }\n",
        "\n",
        "  def call(self,\n",
        "           query_input,\n",
        "           source_input,\n",
        "           bias,\n",
        "           training,\n",
        "           cache=None,\n",
        "           decode_loop_step=None):\n",
        "    \"\"\"Apply attention mechanism to query_input and source_input.\n",
        "    Args:\n",
        "      query_input: A tensor with shape [batch_size, length_query, hidden_size].\n",
        "      source_input: A tensor with shape [batch_size, length_source,\n",
        "        hidden_size].\n",
        "      bias: A tensor with shape [batch_size, 1, length_query, length_source],\n",
        "        the attention bias that will be added to the result of the dot product.\n",
        "      training: A bool, whether in training mode or not.\n",
        "      cache: (Used during prediction) A dictionary with tensors containing\n",
        "        results of previous attentions. The dictionary must have the items:\n",
        "            {\"k\": tensor with shape [batch_size, i, heads, dim_per_head],\n",
        "             \"v\": tensor with shape [batch_size, i, heads, dim_per_head]} where\n",
        "               i is the current decoded length for non-padded decode, or max\n",
        "               sequence length for padded decode.\n",
        "      decode_loop_step: An integer, step number of the decoding loop. Used only\n",
        "        for autoregressive inference on TPU.\n",
        "    Returns:\n",
        "      Attention layer output with shape [batch_size, length_query, hidden_size]\n",
        "    \"\"\"\n",
        "    # Linearly project the query, key and value using different learned\n",
        "    # projections. Splitting heads is automatically done during the linear\n",
        "    # projections --> [batch_size, length, num_heads, dim_per_head].\n",
        "    query = self.query_dense_layer(query_input)\n",
        "    key = self.key_dense_layer(source_input)\n",
        "    value = self.value_dense_layer(source_input)\n",
        "\n",
        "    if self.projection_matrix_type is None:\n",
        "      projection_matrix = None\n",
        "    else:\n",
        "      dim = query.shape[-1]\n",
        "      seed = tf.math.ceil(tf.math.abs(tf.math.reduce_sum(query) * BIG_CONSTANT))\n",
        "      seed = tf.dtypes.cast(seed, tf.int32)\n",
        "      projection_matrix = create_projection_matrix(\n",
        "          self.nb_random_features, dim, seed=seed)\n",
        "\n",
        "    if cache is not None:\n",
        "      # Combine cached keys and values with new keys and values.\n",
        "      if decode_loop_step is not None:\n",
        "        cache_k_shape = cache[\"k\"].shape.as_list()\n",
        "        indices = tf.reshape(\n",
        "            tf.one_hot(decode_loop_step, cache_k_shape[1], dtype=key.dtype),\n",
        "            [1, cache_k_shape[1], 1, 1])\n",
        "        key = cache[\"k\"] + key * indices\n",
        "        cache_v_shape = cache[\"v\"].shape.as_list()\n",
        "        indices = tf.reshape(\n",
        "            tf.one_hot(decode_loop_step, cache_v_shape[1], dtype=value.dtype),\n",
        "            [1, cache_v_shape[1], 1, 1])\n",
        "        value = cache[\"v\"] + value * indices\n",
        "      else:\n",
        "        key = tf.concat([tf.cast(cache[\"k\"], key.dtype), key], axis=1)\n",
        "        value = tf.concat([tf.cast(cache[\"v\"], value.dtype), value], axis=1)\n",
        "\n",
        "      # Update cache\n",
        "      cache[\"k\"] = key\n",
        "      cache[\"v\"] = value\n",
        "\n",
        "    attention_output = favor_attention(query, key, value,\n",
        "                                       self.kernel_transformation, self.causal,\n",
        "                                       projection_matrix)\n",
        "    attention_output = self.output_dense_layer(attention_output)\n",
        "    return attention_output\n",
        "\n",
        "\n",
        "class SelfAttention(Attention):\n",
        "  \"\"\"Multiheaded self-attention layer.\"\"\"\n",
        "\n",
        "  def call(self,\n",
        "           query_input,\n",
        "           bias,\n",
        "           training,\n",
        "           cache=None,\n",
        "           decode_loop_step=None):\n",
        "    return super(SelfAttention, self).call(query_input, query_input, bias,\n",
        "                                           training, cache, decode_loop_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRlFJ1xynH5h"
      },
      "outputs": [],
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x) \n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqAOHEePeoKm"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    #IMPORTANT CHANGE: obv we added code that is different from the og attention model above, but this is \n",
        "    #the main change within the framework from the original transformer_v2 model, we just call the new \n",
        "    #self attention class instead of the traditional self attention \n",
        "    self.self_attention = SelfAttention(\n",
        "        hidden_size=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout_rate=dropout_rate)\n",
        "        #kernel_transformation = softmax_kernel_transformation\n",
        "    \n",
        "    self.causal_self_attention = SelfAttention(\n",
        "        causal = True,\n",
        "        hidden_size=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout_rate=dropout_rate)\n",
        "        #kernel_transformation = softmax_kernel_transformation    \n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    bias = tf.ones([1])\n",
        "    print('eh',x.shape)\n",
        "    x = self.self_attention(x,bias,training=True)\n",
        "    print(x.shape)\n",
        "    x = self.causal_self_attention(x,bias,training=True)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "261ko-x0eoKm",
        "outputId": "a53a65f7-dbe1-43be-d748-c06926083ecd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(336, 1683)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[ 2.  0.  0. ...  0.  0.  0.]\n",
            " [ 1.  0.  0. ...  1.  1.  0.]\n",
            " [ 3.  1.  0. ...  1.  0.  0.]\n",
            " ...\n",
            " [46. 11.  8. ... 18.  7. 19.]\n",
            " [38.  6.  2. ... 15.  2. 11.]\n",
            " [21. 17.  5. ... 17.  7. 10.]], shape=(336, 1683), dtype=float32)\n",
            "(336, 1)\n",
            "(336, 1683)\n",
            "(336, 1683)\n",
            "(336, 1683)\n",
            "(323, 13, 1683)\n"
          ]
        }
      ],
      "source": [
        "x1_df_test = x1_df[0:336]\n",
        "x1_df_test_time = x1_df_test[:,-1]\n",
        "x1_test_data = df[STREETS][0:336].to_numpy()\n",
        "print()\n",
        "positional_em = PositionalEmbedding(x1_df_test_time,0.4)\n",
        "x1_test, y1_test = positional_em(x1_test_data)\n",
        "print(x1_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDSC8tEreoKm",
        "outputId": "2ca0a4ef-5e41-469c-e41f-5dbe8efef4be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(336, 1683)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[ 2.  0.  0. ...  0.  0.  0.]\n",
            " [ 1.  0.  0. ...  1.  1.  0.]\n",
            " [ 3.  1.  0. ...  1.  0.  0.]\n",
            " ...\n",
            " [46. 11.  8. ... 18.  7. 19.]\n",
            " [38.  6.  2. ... 15.  2. 11.]\n",
            " [21. 17.  5. ... 17.  7. 10.]], shape=(336, 1683), dtype=float32)\n",
            "(336, 1)\n",
            "(336, 1683)\n",
            "(336, 1683)\n",
            "(336, 1683)\n",
            "(323, 13, 1683)\n",
            "eh (323, 13, 1683)\n",
            "(323, 13, 1683)\n",
            "(323, 13, 1683)\n"
          ]
        }
      ],
      "source": [
        "sample_encoder_layer = EncoderLayer(d_model=keys_dim, num_heads=9, dff=keys_dim)\n",
        "encoder_test = positional_em(x1_test_data)[0]\n",
        "print(encoder_test.shape)\n",
        "print(sample_encoder_layer(encoder_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLOxGvXyeoKm"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(\n",
        "                    d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff\n",
        "                     )\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` is token-IDs shape: (batch, seq_len)\n",
        "    print('try embedd',x.shape)\n",
        "\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      print()\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlLO67jOeoKm",
        "outputId": "a2a6cd13-0602-42e4-a678-39a1a48f3dc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "try embedd (323, 13, 1683)\n",
            "\n",
            "eh (323, 13, 1683)\n",
            "(323, 13, 1683)\n",
            "\n",
            "eh (323, 13, 1683)\n",
            "(323, 13, 1683)\n",
            "(323, 13, 1683)\n",
            "(323, 13, 1683)\n"
          ]
        }
      ],
      "source": [
        "sample_encoder = Encoder(num_layers=2,\n",
        "                         d_model=keys_dim,\n",
        "                         num_heads=3,\n",
        "                         dff=keys_dim\n",
        "                         )\n",
        "\n",
        "sample_encoder_output = sample_encoder(encoder_test, training=False)\n",
        "\n",
        "# Print the shape.\n",
        "print(encoder_test.shape)\n",
        "print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY5N-ebf6pBe"
      },
      "outputs": [],
      "source": [
        "#encoder only transformer \n",
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           dropout_rate=dropout_rate)\n",
        "    #flattening before the final layer \n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.final_layer = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    print('input_shape',inputs.shape)\n",
        "    x = inputs\n",
        "    x = self.encoder(x)  # (batch_size, target_len, d_model)\n",
        "    \n",
        "\n",
        "    # Final linear layer output.\n",
        "    x = self.flatten(x)\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    \n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfDPZTNreoKm"
      },
      "outputs": [],
      "source": [
        "num_layers = 2\n",
        "d_model = keys_dim\n",
        "dff = keys_dim\n",
        "num_heads = 3\n",
        "dropout_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfxrE5uYeoKm"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    dropout_rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0K8Y1LReoKm",
        "outputId": "d22d7dd2-e84b-43d0-a734-088bb8c99bd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2832, 1684)\n",
            "(283, 1684)\n"
          ]
        }
      ],
      "source": [
        "print(x1_df.shape)\n",
        "length = 2832\n",
        "#80, 10, 10 split from train val test \n",
        "val_step = int(0.1 * length) * 2\n",
        "test_step = int(0.1 * length)\n",
        "\n",
        "val_s = length - val_step\n",
        "test_s = length - test_step\n",
        "\n",
        "x_train = x1_df[:val_s]\n",
        "x_val = x1_df[val_s:test_s]\n",
        "x_test= x1_df[test_s:]\n",
        "\n",
        "\n",
        "\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2jF2kcjeoKm",
        "outputId": "094c9b4d-5545-4939-d177-b5e3928685f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(283, 1684)\n",
            "(283, 1684)\n",
            "(283,)\n",
            "(2266, 1683)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[2. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 1. 1. 0.]\n",
            " [3. 1. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [5. 1. 0. ... 2. 0. 0.]\n",
            " [1. 1. 0. ... 0. 1. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]], shape=(2266, 1683), dtype=float32)\n",
            "(2266, 1)\n",
            "(2266, 1683)\n",
            "(2266, 1683)\n",
            "(2266, 1683)\n",
            "(283, 1683)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[ 2.  1.  0. ...  0.  0.  2.]\n",
            " [ 2.  1.  0. ...  3.  1.  8.]\n",
            " [ 1.  2.  1. ...  5.  0.  8.]\n",
            " ...\n",
            " [19. 11.  1. ... 19.  1. 12.]\n",
            " [26. 16.  2. ...  4.  1. 14.]\n",
            " [29. 11.  4. ... 11.  0. 11.]], shape=(283, 1683), dtype=float32)\n",
            "(283, 1)\n",
            "(283, 1683)\n",
            "(283, 1683)\n",
            "(283, 1683)\n",
            "(283, 1683)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[31. 23.  1. ... 13.  8. 17.]\n",
            " [48. 20.  5. ... 17.  3. 20.]\n",
            " [47. 27.  6. ...  7.  2. 20.]\n",
            " ...\n",
            " [31. 14.  4. ... 19.  8. 13.]\n",
            " [29. 16.  1. ... 16.  6. 27.]\n",
            " [21. 27.  6. ... 14.  4. 15.]], shape=(283, 1683), dtype=float32)\n",
            "(283, 1)\n",
            "(283, 1683)\n",
            "(283, 1683)\n",
            "(283, 1683)\n"
          ]
        }
      ],
      "source": [
        "#positionally encode and divide all data sets into batches \n",
        "train_time = x_train[:,-1]\n",
        "train_feat = x_train[:,:-1]\n",
        "val_time = x_val[:,-1]\n",
        "val_feat = x_val[:,:-1]\n",
        "test_time = x_test[:,-1]\n",
        "test_feat = x_test[:,:-1]\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)\n",
        "print(test_time.shape)\n",
        "\n",
        "train_pos_enc = PositionalEmbedding(train_time,0.2)\n",
        "val_pos_enc = PositionalEmbedding(val_time,0.2)\n",
        "test_pos_enc = PositionalEmbedding(test_time,0.2)\n",
        "\n",
        "\n",
        "x_train,y_train = train_pos_enc(np.asarray(train_feat).astype('float32'))\n",
        "x_val,y_val = val_pos_enc(np.asarray(val_feat).astype('float32'))\n",
        "x_test,y_test = test_pos_enc(np.asarray(test_feat).astype('float32'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6M41g0feoKm",
        "outputId": "7bfb47b4-8de9-4922-cac8-9664e4d82940",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "270"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "tf.shape(x_test).numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KrlU5syeoKn",
        "outputId": "dfacde93-464d-4d79-86b7-b8b21cc5a9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0.00763359], shape=(1,), dtype=float64)\n",
            "tf.Tensor(\n",
            "[0.11369401 0.11369401 0.12334981 0.12334981 0.12921221 0.12921221\n",
            " 0.13084641 0.13084641 0.12813121 0.12813121 0.12737486 0.12737486\n",
            " 0.11076575], shape=(13,), dtype=float64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(x_train[0,:,2])\n",
        "\n",
        "plt.scatter(12,y_train[0,:,2])\n",
        "print(y_train[0,:,2])\n",
        "print(x_train[0,:,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QclydFsweoKn",
        "outputId": "0d324906-d8db-4826-f46a-c48423e902d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 13, 1683), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1, 1683), dtype=tf.float64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(64)\n",
        "val_dataloader = tf.data.Dataset.from_tensor_slices((x_val, y_val)).shuffle(10000).batch(64)\n",
        "test_dataloader = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(64)\n",
        "\n",
        "train_batch_size = 2253\n",
        "val_batch_size = 270\n",
        "test_batch_size = 270\n",
        "\n",
        "print(train_dataloader)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WCueYWGeoKn"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader, model, log=False):\n",
        "    for traffic_batch, labels_batch in dataloader:\n",
        "        traffic = traffic_batch\n",
        "        print(traffic.shape)\n",
        "        predict_flow = model(traffic)\n",
        "        mse = tf.keras.losses.MeanSquaredError()\n",
        "        mse = mse(labels_batch,predict_flow ).numpy()\n",
        "    \n",
        "    return predict_flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WiTRTQaeoKn",
        "outputId": "21c4e2d6-9fcc-4fd4-8146-76436c5f98e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 13, 1683)\n",
            "input_shape (64, 13, 1683)\n",
            "try embedd (64, 13, 1683)\n",
            "\n",
            "eh (64, 13, 1683)\n",
            "(64, 13, 1683)\n",
            "\n",
            "eh (64, 13, 1683)\n",
            "(64, 13, 1683)\n",
            "(64, 13, 1683)\n",
            "input_shape (64, 13, 1683)\n",
            "try embedd (64, 13, 1683)\n",
            "\n",
            "eh (64, 13, 1683)\n",
            "(64, 13, 1683)\n",
            "\n",
            "eh (64, 13, 1683)\n",
            "(64, 13, 1683)\n",
            "(64, 13, 1683)\n",
            "input_shape (64, 13, 1683)\n",
            "try embedd (64, 13, 1683)\n",
            "\n",
            "eh (64, 13, 1683)\n",
            "(64, 13, 1683)\n",
            "\n",
            "eh (64, 13, 1683)\n",
            "(64, 13, 1683)\n",
            "(64, 13, 1683)\n",
            "input_shape (64, 13, 1683)\n",
            "try embedd (64, 13, 1683)\n",
            "\n",
            "eh (64, 13, 1683)\n",
            "(64, 13, 1683)\n",
            "\n",
            "eh (64, 13, 1683)\n",
            "(64, 13, 1683)\n",
            "(14, 13, 1683)\n",
            "input_shape (14, 13, 1683)\n",
            "try embedd (14, 13, 1683)\n",
            "\n",
            "eh (14, 13, 1683)\n",
            "(14, 13, 1683)\n",
            "\n",
            "eh (14, 13, 1683)\n",
            "(14, 13, 1683)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(14, 1683), dtype=float32, numpy=\n",
              "array([[ 2.1078656 ,  1.4707577 ,  0.24937041, ..., -1.5736196 ,\n",
              "        -0.34813488, -2.259883  ],\n",
              "       [ 2.0983794 ,  1.4547632 ,  0.2851863 , ..., -1.594801  ,\n",
              "        -0.31703827, -2.2555804 ],\n",
              "       [ 2.1094072 ,  1.4592313 ,  0.3000597 , ..., -1.6126561 ,\n",
              "        -0.30316862, -2.222311  ],\n",
              "       ...,\n",
              "       [ 2.1343682 ,  1.3320897 ,  0.5482021 , ..., -1.7556384 ,\n",
              "        -0.67586446, -1.9976751 ],\n",
              "       [ 2.210704  ,  1.3843462 ,  0.5623695 , ..., -1.7627736 ,\n",
              "        -0.7669524 , -1.9749743 ],\n",
              "       [ 2.2808592 ,  1.4373529 ,  0.52113485, ..., -1.7706354 ,\n",
              "        -0.8728185 , -1.9244938 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "evaluate(test_dataloader,transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDMEHkdWeoKn"
      },
      "outputs": [],
      "source": [
        "def loss(y_true, y_pred):\n",
        "    mse = tf.keras.losses.MeanSquaredError()\n",
        "    y = mse(y_true, y_pred)\n",
        "    return y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tngOZr8reoKn"
      },
      "outputs": [],
      "source": [
        "transformer.compile(optimizer=optimizer, \n",
        "                  loss = tf.keras.losses.MeanSquaredError(), \n",
        "                  metrics= [tf.keras.losses.MeanSquaredError()]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3KB5CXjeoKn",
        "outputId": "8a0553c0-e357-492e-9b7f-ef4fba42247a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "input_shape (None, 13, 1683)\n",
            "try embedd (None, 13, 1683)\n",
            "\n",
            "eh (None, 13, 1683)\n",
            "(None, 13, 1683)\n",
            "\n",
            "eh (None, 13, 1683)\n",
            "(None, 13, 1683)\n",
            "input_shape (None, 13, 1683)\n",
            "try embedd (None, 13, 1683)\n",
            "\n",
            "eh (None, 13, 1683)\n",
            "(None, 13, 1683)\n",
            "\n",
            "eh (None, 13, 1683)\n",
            "(None, 13, 1683)\n",
            "36/36 [==============================] - ETA: 0s - loss: 28.2540 - mean_squared_error: 27.6596 input_shape (None, 13, 1683)\n",
            "try embedd (None, 13, 1683)\n",
            "\n",
            "eh (None, 13, 1683)\n",
            "(None, 13, 1683)\n",
            "\n",
            "eh (None, 13, 1683)\n",
            "(None, 13, 1683)\n",
            "36/36 [==============================] - 712s 19s/step - loss: 28.2540 - mean_squared_error: 27.6596 - val_loss: 0.6505 - val_mean_squared_error: 0.6494\n",
            "Epoch 2/7\n",
            "36/36 [==============================] - 712s 20s/step - loss: 0.5011 - mean_squared_error: 0.4960 - val_loss: 0.1150 - val_mean_squared_error: 0.1168\n",
            "Epoch 3/7\n",
            "36/36 [==============================] - 813s 23s/step - loss: 0.2511 - mean_squared_error: 0.2506 - val_loss: 0.1040 - val_mean_squared_error: 0.1090\n",
            "Epoch 4/7\n",
            "36/36 [==============================] - 674s 19s/step - loss: 0.2447 - mean_squared_error: 0.2448 - val_loss: 0.1080 - val_mean_squared_error: 0.1099\n",
            "Epoch 5/7\n",
            "36/36 [==============================] - 720s 20s/step - loss: 0.2453 - mean_squared_error: 0.2452 - val_loss: 0.1000 - val_mean_squared_error: 0.0986\n",
            "Epoch 6/7\n",
            "33/36 [==========================>...] - ETA: 1:00 - loss: 0.2461 - mean_squared_error: 0.2461"
          ]
        }
      ],
      "source": [
        "transformer.fit(train_dataloader,epochs = 7,validation_data = val_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bcd8i_7JwpLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5ctLDoweoKn"
      },
      "outputs": [],
      "source": [
        "response = evaluate(test_dataloader,transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dd24qZ9VeoKn"
      },
      "outputs": [],
      "source": [
        "res = transformer.predict(x_test)\n",
        "res[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq-TBPPzeoKn"
      },
      "outputs": [],
      "source": [
        "res2 = tf.reduce_mean(res,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgWRZuD-eoKn"
      },
      "outputs": [],
      "source": [
        "plt.plot(res2)\n",
        "#plt.plot(tf.reduce_mean(y_test,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1ys0BTneoKn"
      },
      "outputs": [],
      "source": [
        "print(max(res2))\n",
        "print(min(res2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "39282081ff6844baad5334981d710ee8987f21358ca5c4d02825da922a75398f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}